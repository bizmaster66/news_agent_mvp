import json
import shutil
import sys
import uuid
from datetime import datetime, timedelta, time
from pathlib import Path

import streamlit as st
from dateutil import tz

ROOT = Path(__file__).parent
sys.path.append(str(ROOT))

from src.news_fetcher import fetch_articles  # noqa: E402

DATA_DIR = ROOT / "data"
RUNS_DIR = DATA_DIR / "runs"
SETTINGS_PATH = DATA_DIR / "settings_current.json"

KST = tz.gettz("Asia/Seoul")


def now_kst() -> datetime:
    return datetime.now(tz=KST)


def ensure_dirs():
    DATA_DIR.mkdir(parents=True, exist_ok=True)
    RUNS_DIR.mkdir(parents=True, exist_ok=True)


def load_settings() -> dict:
    if not SETTINGS_PATH.exists():
        return {}
    return json.loads(SETTINGS_PATH.read_text(encoding="utf-8"))


def save_settings(settings: dict):
    settings["updated_at"] = now_kst().isoformat()
    SETTINGS_PATH.write_text(json.dumps(settings, ensure_ascii=False, indent=2), encoding="utf-8")


def get_default_window(settings: dict):
    win = settings.get("default_run_window", {})
    start_s = win.get("start_time", "08:00:00")
    end_s = win.get("end_time", "07:59:59")

    def parse_hms(hms: str) -> time:
        hh, mm, ss = [int(x) for x in hms.split(":")]
        return time(hh, mm, ss)

    today = now_kst().date()
    start_dt = datetime.combine(today - timedelta(days=1), parse_hms(start_s), tzinfo=KST)
    end_dt = datetime.combine(today, parse_hms(end_s), tzinfo=KST)
    return start_dt, end_dt


def safe_slug(s: str) -> str:
    return "".join(ch if ch.isalnum() or ch in "-_." else "_" for ch in s)


def make_run_folder(start_dt: datetime, end_dt: datetime) -> Path:
    run_id = f"run-{uuid.uuid4().hex[:8]}"
    folder_name = f"{start_dt.strftime('%Y-%m-%d_%H%M%S')}__{end_dt.strftime('%Y-%m-%d_%H%M%S')}__{run_id}"
    path = RUNS_DIR / safe_slug(folder_name)
    path.mkdir(parents=True, exist_ok=False)
    return path


def list_runs():
    if not RUNS_DIR.exists():
        return []
    runs = [p for p in RUNS_DIR.iterdir() if p.is_dir() and (p / "run.json").exists()]
    runs.sort(key=lambda x: x.name, reverse=True)
    return runs


def read_json(path: Path):
    return json.loads(path.read_text(encoding="utf-8"))


def write_json(path: Path, obj: dict):
    path.write_text(json.dumps(obj, ensure_ascii=False, indent=2), encoding="utf-8")


def delete_run_folder(run_path: Path):
    shutil.rmtree(run_path)


st.set_page_config(page_title="News Agent MVP", layout="wide")
ensure_dirs()

st.sidebar.title("News Agent MVP")
page = st.sidebar.radio("ë©”ë‰´", ["Run", "Result", "History", "Settings"])

settings = load_settings()


# -----------------------------
# Page: Run
# -----------------------------
if page == "Run":
    st.header("Run: ê¸°ê°„ì„ ì„ íƒí•˜ê³  ì‹¤í–‰")

    if not settings:
        st.error("data/settings_current.jsonì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
        st.stop()

    default_start, default_end = get_default_window(settings)

    col1, col2 = st.columns(2)
    with col1:
        start_date = st.date_input("ì‹œì‘ ë‚ ì§œ (KST)", value=default_start.date())
        start_time = st.time_input("ì‹œì‘ ì‹œê°„ (KST)", value=default_start.timetz().replace(tzinfo=None))
    with col2:
        end_date = st.date_input("ì¢…ë£Œ ë‚ ì§œ (KST)", value=default_end.date())
        end_time = st.time_input("ì¢…ë£Œ ì‹œê°„ (KST)", value=default_end.timetz().replace(tzinfo=None))

    start_dt = datetime.combine(start_date, start_time, tzinfo=KST)
    end_dt = datetime.combine(end_date, end_time, tzinfo=KST)

    if end_dt <= start_dt:
        st.warning("ì¢…ë£Œ ì‹œê°„ì´ ì‹œì‘ ì‹œê°„ë³´ë‹¤ ì´í›„ì—¬ì•¼ í•©ë‹ˆë‹¤.")
        st.stop()

    st.caption("MVP: RSS ìˆ˜ì§‘ â†’ ê¸°ê°„ í•„í„° â†’ (í›„ë³´ë§Œ) ì›ë¬¸ í¬ë¡¤ë§ â†’ articles.jsonl ì €ì¥")

    if st.button("ì‹¤í–‰ (RSS ìˆ˜ì§‘ & ì €ì¥)"):
        run_path = make_run_folder(start_dt, end_dt)

        with st.spinner("RSS ìˆ˜ì§‘ ë° ì²˜ë¦¬ ì¤‘..."):
            result = fetch_articles(settings, start_dt, end_dt)

        stats = dict(result.get("stats", {}))
        stats.setdefault("dedup_before", stats.get("after_time_filter", 0))
        stats.setdefault("dedup_after", stats.get("after_time_filter", 0))

        run_meta = {
            "run_id": run_path.name.split("__")[-1],
            "start_ts": start_dt.isoformat(),
            "end_ts": end_dt.isoformat(),
            "created_at": now_kst().isoformat(),
            "status": "succeeded",
            "settings_snapshot": settings,
            "stats": stats,
        }
        write_json(run_path / "run.json", run_meta)

        # articles.jsonl ì €ì¥
        with open(run_path / "articles.jsonl", "w", encoding="utf-8") as f:
            for a in result.get("articles", []):
                f.write(json.dumps(a, ensure_ascii=False) + "\n")

        # ê²°ê³¼ íŒŒì¼ ê¸°ë³¸ ìƒì„±(ì—†ìœ¼ë©´)
        if not (run_path / "curations.json").exists():
            write_json(run_path / "curations.json", {})
        if not (run_path / "theme_summaries.json").exists():
            write_json(run_path / "theme_summaries.json", {})

        st.success(f"ìˆ˜ì§‘ ì™„ë£Œ: {len(result.get('articles', []))}ê°œ ê¸°ì‚¬ ì €ì¥")
        st.info(f"Run: {run_path.name}")
        st.info("Result íƒ­ì—ì„œ í™•ì¸í•˜ì„¸ìš”.")


# -----------------------------
# Page: Result
# -----------------------------
elif page == "Result":
    st.header("Result: ì‹¤í–‰ ê²°ê³¼ ë³´ê¸°")

    runs = list_runs()
    if not runs:
        st.info("ì•„ì§ ìƒì„±ëœ Runì´ ì—†ìŠµë‹ˆë‹¤. Run íƒ­ì—ì„œ ì‹¤í–‰ì„ ë¨¼ì € í•´ì£¼ì„¸ìš”.")
        st.stop()

    run_names = [p.name for p in runs]
    selected = st.selectbox("Run ì„ íƒ", run_names, index=0)
    run_path = RUNS_DIR / selected

    run_meta = read_json(run_path / "run.json")
    st.subheader("Run ì •ë³´")
    st.json(
        {
            "run_id": run_meta.get("run_id"),
            "period": [run_meta.get("start_ts"), run_meta.get("end_ts")],
            "created_at": run_meta.get("created_at"),
            "status": run_meta.get("status"),
            "stats": run_meta.get("stats", {}),
        }
    )

    st.divider()

    # ---- Actions: curate / summarize (cloud-safe direct call) ----
    st.subheader("Actions")

    import io, contextlib, traceback
    from pathlib import Path
    from src import curate_rule, summarize_top15

    def run_and_show(label, fn):
        st.toast(label)
        buf = io.StringIO()
        with st.spinner(label):
            try:
                with contextlib.redirect_stdout(buf), contextlib.redirect_stderr(buf):
                    fn()
            except Exception:
                traceback.print_exc(file=buf)
        out = buf.getvalue().strip()
        if out:
            st.code(out)
        else:
            st.info("ì™„ë£Œ(ì¶œë ¥ ì—†ìŒ)")
        st.rerun()

    c1, c2, c3 = st.columns([2,2,6])
    with c1:
        if st.button("íë ˆì´ì…˜ ìƒì„± (curate)", key=f"curate_{run_path.name}"):
            run_and_show(
                "íë ˆì´ì…˜ ìƒì„± ì¤‘...",
                lambda: curate_rule.main(Path(run_path), sim_threshold=0.60, k_neighbors=20, candidate_cap=80)
            )
    with c2:
        if st.button("ìš”ì•½ ìƒì„± (force)", key=f"sum_{run_path.name}"):
            run_and_show(
                "ìš”ì•½ ìƒì„± ì¤‘...",
                lambda: summarize_top15.main(Path(run_path), sleep_sec=0.2, force=True)
            )
    with c3:
        st.caption("â€» Settings ë³€ê²½ í›„, ê°™ì€ Runì— ë°˜ì˜í•˜ë ¤ë©´ curate â†’ summarizeë¥¼ ë‹¤ì‹œ ì‹¤í–‰í•˜ì„¸ìš”.")


    # ---- Actions: curate / summarize (no terminal) ----
    

st.subheader("ìˆ˜ì§‘ ê¸°ì‚¬ (ì¼ë¶€ 30ê°œ ë¯¸ë¦¬ë³´ê¸°)")
    articles_file = run_path / "articles.jsonl"
    if articles_file.exists():
        rows = []
        with open(articles_file, "r", encoding="utf-8") as f:
            for idx, line in enumerate(f):
                if idx >= 30:
                    break
                if line.strip():
                    rows.append(json.loads(line))

        if not rows:
            st.info("articles.jsonlì´ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤.")
        else:
            for r in rows:
                source = r.get("source_name", "")
                title = r.get("title", "")
                url = r.get("final_url") or r.get("resolved_url") or r.get("google_news_url") or ""
                if url:
                    st.markdown(f"**[{source} - {title}]({url})**")
                else:
                    st.markdown(f"**{source} - {title}**")
                st.caption(
                    f"pubDate: {r.get('pubdate_ts') or r.get('pubdate_raw') or 'unknown'} | crawl: {r.get('crawl_status')}"
                )
                st.markdown("---")
    else:
        st.info("articles.jsonlì´ ì•„ì§ ì—†ìŠµë‹ˆë‹¤.")

    st.divider()

    # ---- í…Œë§ˆë³„ ìš”ì•½ & íë ˆì´ì…˜ ----
    theme_summaries_path = run_path / "theme_summaries.json"
    curations_path = run_path / "curations.json"

    theme_summaries = read_json(theme_summaries_path) if theme_summaries_path.exists() else {}
    curations = read_json(curations_path) if curations_path.exists() else {}

    st.subheader("í…Œë§ˆë³„ ìš”ì•½ (10ì¤„)")
    if not theme_summaries:
        st.info("ì•„ì§ í…Œë§ˆ ìš”ì•½ì´ ì—†ìŠµë‹ˆë‹¤.")
    else:
        for theme, obj in theme_summaries.items():
            st.markdown(f"### {theme}")
            lines = obj.get("lines", [])
            if lines:
                st.write("\n".join(lines))
            st.markdown("---")

    st.subheader("í…Œë§ˆë³„ Top 15 íë ˆì´ì…˜")
    if not curations:
        st.info("ì•„ì§ íë ˆì´ì…˜ì´ ì—†ìŠµë‹ˆë‹¤.")
    else:
        for theme, items in curations.items():
            st.markdown(f"### {theme}")

            if not items:
                st.caption("í•´ë‹¹ í…Œë§ˆì— íë ˆì´ì…˜ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
                st.markdown("---")
                continue

            for it in items[:15]:
                source = it.get("source_name", "")
                title = it.get("title", "")
                url = it.get("url", "")
                pub = it.get("pubdate_ts", "")
                score = it.get("score", "")

                if url:
                    st.markdown(f"**[{source} - {title}]({url})**")
                else:
                    st.markdown(f"**{source} - {title}**")

                meta = []
                if pub:
                    meta.append(f"ğŸ•’ {pub}")
                if score != "":
                    try:
                        meta.append(f"â­ {float(score):.2f}")
                    except Exception:
                        meta.append(f"â­ {score}")
                if meta:
                    st.caption(" | ".join(meta))

                summary_text = (it.get("summary_text") or "").strip()
                if summary_text:
                    st.write(summary_text)
                else:
                    s3 = it.get("summary_3_lines") or []
                    if s3:
                        st.write(" ".join([x.strip() for x in s3 if x and x.strip()]))
                st.markdown("---")

            st.divider()


# -----------------------------
# Page: History
# -----------------------------
elif page == "History":
    st.header("History: Run ëª©ë¡ ë° ì‚­ì œ")

    runs = list_runs()
    if not runs:
        st.info("ì•„ì§ ìƒì„±ëœ Runì´ ì—†ìŠµë‹ˆë‹¤.")
        st.stop()

    for pth in runs:
        cols = st.columns([6, 2, 2])
        with cols[0]:
            st.write(pth.name)
        with cols[1]:
            try:
                run_meta = read_json(pth / "run.json")
                st.caption(run_meta.get("created_at", ""))
            except Exception:
                st.caption("run.json ì½ê¸° ì‹¤íŒ¨")
        with cols[2]:
            if st.button("ì‚­ì œ", key=f"del_{pth.name}"):
                delete_run_folder(pth)
                st.success(f"ì‚­ì œ ì™„ë£Œ: {pth.name}")
                st.rerun()


# -----------------------------
# Page: Settings
# -----------------------------
else:
    st.header("Settings: ë§¤ì²´/í…Œë§ˆ/í‚¤ì›Œë“œ ì„¤ì •")

    if not settings:
        st.error("settings_current.jsonì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
        st.stop()

    st.caption("ì„¤ì • ë³€ê²½ì€ ë‹¤ìŒ Runë¶€í„° ë°˜ì˜ë©ë‹ˆë‹¤.")

    tab1, tab2 = st.tabs(["ë§¤ì²´", "í…Œë§ˆ/í‚¤ì›Œë“œ"])

    with tab1:
        st.subheader("ë§¤ì²´ ëª©ë¡")
        media = settings.get("media_sources", [])
        st.write(f"ì´ {len(media)}ê°œ")

        for i, m in enumerate(media):
            with st.expander(f"{m.get('name')} ({m.get('domain')})", expanded=False):
                m["enabled"] = st.checkbox("í™œì„±", value=bool(m.get("enabled", True)), key=f"media_en_{i}")
                m["group"] = st.selectbox(
                    "ê·¸ë£¹",
                    options=["startup", "it", "econ", "daily"],
                    index=["startup", "it", "econ", "daily"].index(m.get("group", "econ"))
                    if m.get("group") in ["startup", "it", "econ", "daily"]
                    else 2,
                    key=f"media_group_{i}",
                )

        st.divider()
        st.subheader("ë§¤ì²´ ì¶”ê°€")
        new_domain = st.text_input("ë„ë©”ì¸ (ì˜ˆ: example.com)")
        new_name = st.text_input("ë§¤ì²´ëª… (ì˜ˆ: ì˜ˆì‹œë‰´ìŠ¤)")
        new_group = st.selectbox("ê·¸ë£¹", ["startup", "it", "econ", "daily"], index=2)

        if st.button("ë§¤ì²´ ì¶”ê°€"):
            if new_domain and new_name:
                settings["media_sources"].append(
                    {"domain": new_domain.strip(), "name": new_name.strip(), "group": new_group, "enabled": True}
                )
                save_settings(settings)
                st.success("ë§¤ì²´ ì¶”ê°€ ì™„ë£Œ")
                st.rerun()
            else:
                st.warning("ë„ë©”ì¸ê³¼ ë§¤ì²´ëª…ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")

    with tab2:
        st.subheader("í…Œë§ˆ ëª©ë¡")
        themes = settings.get("themes", [])
        st.write(f"ì´ {len(themes)}ê°œ")

        for i, t in enumerate(themes):
            with st.expander(f"{t.get('name')}", expanded=False):
                t["enabled"] = st.checkbox("í™œì„±", value=bool(t.get("enabled", True)), key=f"theme_en_{i}")
                t["name"] = st.text_input("í…Œë§ˆëª…", value=t.get("name", ""), key=f"theme_name_{i}")

                st.markdown("**Include Groups (AND/OR)**")
                st.caption("ê·¸ë£¹ë¼ë¦¬ëŠ” AND, ê·¸ë£¹ ë‚´ë¶€ í‚¤ì›Œë“œëŠ” OR ì…ë‹ˆë‹¤.")
                include_groups = t.get("include_groups", [[]])

                group_lines = []
                for g in include_groups:
                    group_lines.append(", ".join([x for x in g if x]))

                raw_groups = st.text_area(
                    "Include Groups (í•œ ì¤„=í•œ ê·¸ë£¹, ê·¸ë£¹ ë‚´ ORì€ ì½¤ë§ˆ)",
                    value="\n".join(group_lines),
                    height=120,
                    key=f"inc_groups_{i}",
                )
                parsed_groups = []
                for line in raw_groups.splitlines():
                    kws = [x.strip() for x in line.split(",") if x.strip()]
                    if kws:
                        parsed_groups.append(kws)
                t["include_groups"] = parsed_groups if parsed_groups else [[]]

                st.markdown("**Exclude Keywords (OR)**")
                ex_raw = st.text_input(
                    "Exclude (ì½¤ë§ˆë¡œ êµ¬ë¶„)",
                    value=", ".join(t.get("exclude_keywords", [])),
                    key=f"exc_{i}",
                )
                t["exclude_keywords"] = [x.strip() for x in ex_raw.split(",") if x.strip()]

                # í•„ìˆ˜ í¬í•¨(AND): ì•„ë˜ í‚¤ì›Œë“œ 'ëª¨ë‘' í¬í•¨ë˜ì–´ì•¼ í…Œë§ˆ í›„ë³´ë¡œ ì¸ì •
                mi_raw = st.text_input(
                    "í•„ìˆ˜ í¬í•¨ (AND, ì½¤ë§ˆ êµ¬ë¶„) - ëª¨ë‘ í¬í•¨ë˜ì–´ì•¼ í•¨",
                    value=", ".join(t.get("must_include", [])),
                    key=f"must_inc_{i}",
                )
                t["must_include"] = [x.strip() for x in mi_raw.split(",") if x.strip()]

                # í•„ìˆ˜ í¬í•¨(OR): ì•„ë˜ í‚¤ì›Œë“œ ì¤‘ 'í•˜ë‚˜ë¼ë„' í¬í•¨ë˜ë©´ í…Œë§ˆ í›„ë³´ë¡œ ì¸ì •
                mia_raw = st.text_input(
                    "í•„ìˆ˜ í¬í•¨ (OR, ì½¤ë§ˆ êµ¬ë¶„) - í•˜ë‚˜ë¼ë„ í¬í•¨",
                    value=", ".join(t.get("must_include_any", [])),
                    key=f"must_any_{i}",
                )
                t["must_include_any"] = [x.strip() for x in mia_raw.split(",") if x.strip()]


                t["max_items"] = st.number_input(
                    "í…Œë§ˆë³„ ìµœëŒ€ íë ˆì´ì…˜ ìˆ˜",
                    min_value=1,
                    max_value=30,
                    value=int(t.get("max_items", 15)),
                    key=f"max_{i}",
                )

                # (ì„ íƒ) must_includeëŠ” ë‚˜ì¤‘ì— UIì— ì¶”ê°€ ê°€ëŠ¥
                if st.button("ì´ í…Œë§ˆ ì‚­ì œ", key=f"del_theme_{i}"):
                    settings["themes"].pop(i)
                    save_settings(settings)
                    st.success("ì‚­ì œ ì™„ë£Œ")
                    st.rerun()

        st.divider()
        st.subheader("í…Œë§ˆ ì¶”ê°€")
        new_theme_name = st.text_input("ìƒˆ í…Œë§ˆëª…")
        if st.button("í…Œë§ˆ ì¶”ê°€"):
            if new_theme_name.strip():
                settings["themes"].append(
                    {
                        "name": new_theme_name.strip(),
                        "enabled": True,
                        "include_groups": [[]],
                        "exclude_keywords": [],
                        "curation_priority": [],
                        "max_items": 15,
                    }
                )
                save_settings(settings)
                st.success("í…Œë§ˆ ì¶”ê°€ ì™„ë£Œ")
                st.rerun()
            else:
                st.warning("í…Œë§ˆëª…ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")

    st.divider()
    if st.button("ì„¤ì • ì €ì¥"):
        save_settings(settings)
        st.success("ì„¤ì • ì €ì¥ ì™„ë£Œ")
